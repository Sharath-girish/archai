# use this as overriding config for quick compile testing

common:
  detect_anomaly: False # if True, PyTorch code will run 6X slower
  resume: False

nas:
  search:
    data_parallel: False
    resume: False # ignore checkpoint file if it exist
    search_iters: 1
    pareto:
      max_reductions: 2
      max_cells: 5
      max_nodes: 2
      enabled: False
    seed_train:
      trainer:
        epochs: '_copy: /common/toy_mode/seed_train_epochs' # number of epochs model will be trained before search
      loader:
        train_batch: '_copy: /common/toy_mode/train_batch'
        test_batch: '_copy: /common/toy_mode/test_batch'
        dataset:
          max_batches: '_copy: /common/toy_mode/max_batches'
    post_train:
      trainer:
        epochs: '_copy: /common/toy_mode/post_train_epochs'
      loader:
        train_batch: '_copy: /common/toy_mode/train_batch'
        test_batch: '_copy: /common/toy_mode/test_batch'
        dataset:
          max_batches: '_copy: /common/toy_mode/max_batches'
    model_desc:
      n_reductions: 1 # number of reductions to be applied
      n_cells: 3 # number of cells
      cell:
        n_nodes: 2 # number of nodes in a cell
    loader:
      train_batch: '_copy: /common/toy_mode/train_batch'
      test_batch: '_copy: /common/toy_mode/test_batch'
      dataset:
        max_batches: '_copy: /common/toy_mode/max_batches'
    trainer:
      epochs: 1
      logger_freq: 1
      validation:
        logger_freq: 1

  eval:
    data_parallel: False
    checkpoint: null
    model_desc:
      n_cells: 5 # number of cells
      n_reductions: 2 # number of reductions to be applied
      cell:
        n_nodes: 4 # number of nodes in a cell
    loader:
      train_batch: '_copy: /common/toy_mode/train_batch'
      test_batch: '_copy: /common/toy_mode/test_batch'
      dataset:
        max_batches: '_copy: /common/toy_mode/max_batches'
    trainer:
      epochs: 1
      logger_freq: 1
      validation:
        logger_freq: 1

